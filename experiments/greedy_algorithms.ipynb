{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run experiments\n",
    "for each dataset, for each group size and for each group\n",
    "get items from the mf for each member of the group\n",
    "these items will be the input of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 162541)\n",
      "(200, 59047)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(59047, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "u_features = np.load('../datasets/movie_lens/mf/U_features.npy')\n",
    "i_features = np.load('../datasets/movie_lens/mf/I_features.npy')\n",
    "print(u_features.shape)\n",
    "print(i_features.shape)\n",
    "\n",
    "def get_items_for_user(user_id):\n",
    "    items_ratings = u_features[:, user_id] @ i_features\n",
    "    items_ids_w_ratings = [(item_id, rating) for item_id, rating in enumerate(items_ratings)]\n",
    "    items_ids_w_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "    return items_ids_w_ratings\n",
    "\n",
    "def get_items_for_users(users_id: List):\n",
    "    items_ratings = i_features.T @ u_features[:, users_id]\n",
    "    return items_ratings\n",
    "    \n",
    "ratings = get_items_for_users([10,20,30])\n",
    "ratings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "0 2\n",
      "1 2\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "for a, b in itertools.combinations(range(3) , 2):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 52/1000 [00:53<16:13,  1.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 170>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb#ch0000004?line=170'>171</a>\u001b[0m items \u001b[39m=\u001b[39m get_items_for_users(group_members)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb#ch0000004?line=172'>173</a>\u001b[0m \u001b[39m# # avg_algorithm\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb#ch0000004?line=173'>174</a>\u001b[0m \u001b[39m# top_n_items_avg = avg_algorithm(items, 10)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb#ch0000004?line=174'>175</a>\u001b[0m \u001b[39m# rec_it_avg.append(top_n_items_avg)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb#ch0000004?line=183'>184</a>\u001b[0m \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb#ch0000004?line=184'>185</a>\u001b[0m \u001b[39m# xpo_algorithm\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb#ch0000004?line=185'>186</a>\u001b[0m top_n_items_xpo \u001b[39m=\u001b[39m xpo_algorithm(items, \u001b[39m10\u001b[39;49m, \u001b[39m100\u001b[39;49m, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mNPO\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb#ch0000004?line=186'>187</a>\u001b[0m rec_it_xpo\u001b[39m.\u001b[39mappend(top_n_items_xpo)\n",
      "\u001b[1;32m/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb Cell 5\u001b[0m in \u001b[0;36mxpo_algorithm\u001b[0;34m(group_items, top_n, n_candidates, type, mc_trials)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb#ch0000004?line=83'>84</a>\u001b[0m rank_dif \u001b[39m=\u001b[39m rank_of_candidates_a \u001b[39m-\u001b[39m rank_of_candidates_b\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb#ch0000004?line=84'>85</a>\u001b[0m \u001b[39m# for each group member, if a is pareto optimal over b, then all rank_difs will be negative or zero\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb#ch0000004?line=85'>86</a>\u001b[0m \u001b[39m# if b is pareto optimal over 1, then all rank_difs will be positive or zero\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb#ch0000004?line=86'>87</a>\u001b[0m \u001b[39m# and atleast one rank for any group member will negative or positive (non-zero) respectively\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb#ch0000004?line=87'>88</a>\u001b[0m a_paretooptim \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mall(rank_dif \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m) \u001b[39m&\u001b[39m np\u001b[39m.\u001b[39many(rank_dif \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb#ch0000004?line=88'>89</a>\u001b[0m b_paretooptim \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mall(rank_dif \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m&\u001b[39m np\u001b[39m.\u001b[39many(rank_dif \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb#ch0000004?line=89'>90</a>\u001b[0m \u001b[39m# the lower the level the better, as an item, if you are bester (dominated) we lower your level by 1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lada/projects/thesis_analysis/experiments/greedy_algorithms.ipynb#ch0000004?line=90'>91</a>\u001b[0m \u001b[39m# where level 1 is best and level infinity is worst\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mall\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/projects/thesis_analysis/.venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2487\u001b[0m, in \u001b[0;36mall\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2404\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_all_dispatcher)\n\u001b[1;32m   2405\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mall\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, \u001b[39m*\u001b[39m, where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[1;32m   2406\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2407\u001b[0m \u001b[39m    Test whether all array elements along a given axis evaluate to True.\u001b[39;00m\n\u001b[1;32m   2408\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2485\u001b[0m \n\u001b[1;32m   2486\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2487\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mlogical_and, \u001b[39m'\u001b[39;49m\u001b[39mall\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[1;32m   2488\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/projects/thesis_analysis/.venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:70\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrapreduction\u001b[39m(obj, ufunc, method, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 70\u001b[0m     passkwargs \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     71\u001b[0m                   \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue}\n\u001b[1;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(obj) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m mu\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     74\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/thesis_analysis/.venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:71\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrapreduction\u001b[39m(obj, ufunc, method, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     70\u001b[0m     passkwargs \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()\n\u001b[0;32m---> 71\u001b[0m                   \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39;49m_NoValue}\n\u001b[1;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(obj) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m mu\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     74\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def select_top_n(score_list, top_n):\n",
    "    top_n_ind = np.argpartition(score_list, -top_n)[-top_n:]\n",
    "    sorted_top_n_indicies = top_n_ind[np.argsort(-score_list[top_n_ind])]\n",
    "    return sorted_top_n_indicies\n",
    "\n",
    "def get_idx_of_top_n(score_list, top_n):\n",
    "    \"\"\"Returns the indices of the top_n items\"\"\"\n",
    "    top_n_idx = np.argpartition(score_list, -top_n)[-top_n:]\n",
    "    return top_n_idx\n",
    "\n",
    "def avg_algorithm(group_items, top_n: int):\n",
    "    \"\"\"\n",
    "    Returns items ordered by average rating.\n",
    "    \"\"\"\n",
    "    means = group_items.mean(axis=1)\n",
    "    top_n_idx = select_top_n(means, top_n)\n",
    "    return top_n_idx\n",
    "\n",
    "def lm_algorithm(group_items, top_n: int):\n",
    "    \"\"\"\n",
    "    Returns items ordered by least min value across user rating.\n",
    "    \"\"\"\n",
    "    mins = group_items.min(axis=1)\n",
    "    top_n_idx = select_top_n(mins, top_n)\n",
    "    return top_n_idx\n",
    "\n",
    "def fai_algorithm(group_items, top_n: int):\n",
    "    \"\"\"\n",
    "    Returns items ordered by max of users each one by one per turn.\n",
    "    So first item is selected as max of first user, second item by second and so on...\n",
    "    \"\"\"\n",
    "    group_size = group_items.shape[0]\n",
    "    # apply select_top_n to each user\n",
    "    top_n_required_per_user = math.ceil(top_n / group_size)\n",
    "    top_n_idx_per_user = np.apply_along_axis(lambda row: select_top_n(row, top_n_required_per_user), 1, group_items)\n",
    "    # flatten the list to get the turn by turn top_n_idx\n",
    "    top_n = top_n_idx_per_user.flatten(order='F')[:top_n]\n",
    "    return top_n\n",
    "\n",
    "def get_rank(score_list_np):\n",
    "    \"\"\"Best item has a rank of 1\"\"\"\n",
    "    ranks = np.zeros(score_list_np.shape, dtype=np.int32)\n",
    "    ranks[score_list_np.argsort()] = np.arange(start=score_list_np.shape[0], stop=0, step=-1)\n",
    "    return ranks\n",
    "\n",
    "def xpo_algorithm(group_items, top_n: int, n_candidates:int, type:str='XPO', mc_trials:int=1000):\n",
    "    if type != 'XPO' and type != 'NPO':\n",
    "        raise ValueError(f'Unknown type: {type}, only XPO and NPO are supported')\n",
    "\n",
    "    group_size = group_items.shape[1]\n",
    "    # first select top candidates for each member\n",
    "    top_candidates_ids_per_member = np.apply_along_axis(lambda u_items: select_top_n(u_items, n_candidates), 0, group_items)\n",
    "    # these are the original items ids\n",
    "    top_candidates_idx = np.array(sorted(set(top_candidates_ids_per_member.flatten())))\n",
    "\n",
    "    # get the candidate group items for each member\n",
    "    candidate_group_items = group_items[top_candidates_idx, :] # this is the first id mapping (to go back to original, index by top_candidates_idx)\n",
    "\n",
    "    # from now on, item ids are ids into this candidate group items list\n",
    "\n",
    "    # calculate the rank of candidates and all values bigger than n_candidates are set to n_candidates + 1\n",
    "    # ranks will therefore be [1, 101]\n",
    "    rank_of_candidates = np.apply_along_axis(get_rank, 0, candidate_group_items)\n",
    "    rank_of_candidates = np.minimum(rank_of_candidates, n_candidates + 1)\n",
    "\n",
    "    # now we want to compare all pairs of items to calculate the their Pareto optimality level\n",
    "    # we say that item a is pareto optimal over b if for all group members rank(a) <= rank(b)\n",
    "    # they can be both pareto optimal(if their ranks are equal)\n",
    "    # or non-pareto optimal(if their dominate each other for different group members)\n",
    "    number_of_items = len(candidate_group_items)\n",
    "    # print(f'Number of items: {number_of_items}')\n",
    "    pareto_levels = [1] * number_of_items # same ids as candidate_group_items\n",
    "    for a, b in itertools.combinations(range(len(candidate_group_items)) , 2):\n",
    "        rank_of_candidates_a = rank_of_candidates[a]\n",
    "        rank_of_candidates_b = rank_of_candidates[b]\n",
    "\n",
    "        rank_dif = rank_of_candidates_a - rank_of_candidates_b\n",
    "        # for each group member, if a is pareto optimal over b, then all rank_difs will be negative or zero\n",
    "        # if b is pareto optimal over 1, then all rank_difs will be positive or zero\n",
    "        # and atleast one rank for any group member will negative or positive (non-zero) respectively\n",
    "        a_paretooptim = np.all(rank_dif <= 0) & np.any(rank_dif < 0)\n",
    "        b_paretooptim = np.all(rank_dif >= 0) & np.any(rank_dif > 0)\n",
    "        # the lower the level the better, as an item, if you are bester (dominated) we lower your level by 1\n",
    "        # where level 1 is best and level infinity is worst\n",
    "        if a_paretooptim:\n",
    "            pareto_levels[b] += 1\n",
    "        if b_paretooptim:\n",
    "            pareto_levels[a] += 1\n",
    "\n",
    "    # now group the items by pareto level\n",
    "    pareto_levels_pd = pd.DataFrame(enumerate(pareto_levels), columns=['item_id', 'pareto_level'])\n",
    "    pareto_levels_pd = pareto_levels_pd.sort_values(by='pareto_level', ascending=True)\n",
    "\n",
    "    # select candidates by pareto level, cut off at pareto_level = top_n\n",
    "    if type == 'NPO':\n",
    "        final_candidates = pareto_levels_pd[pareto_levels_pd['pareto_level'] <= top_n]['item_id'].explode().to_numpy()\n",
    "\n",
    "    # select candidates starting at pareto level 1 and cut off when the number of candidates is equal or greater than top_n\n",
    "    if type == 'XPO':\n",
    "        # add cumulative count of items to the grouped dataframe\n",
    "        pareto_levels_grouped = pareto_levels_pd.groupby('pareto_level').agg(level=('pareto_level', 'first'), items=('item_id','unique'), items_count=('item_id','count'))\n",
    "        pareto_levels_grouped['cum_items_count'] = pareto_levels_grouped['items_count'].cumsum()\n",
    "        idx_of_first_larger_than_top_k = (pareto_levels_grouped['cum_items_count'] > top_n).idxmax()\n",
    "        # select all pareto levels that will get us top_n items and explode the lists to get the top_n items\n",
    "        final_candidates = pareto_levels_grouped.iloc[0:idx_of_first_larger_than_top_k]['items'].explode().to_numpy()\n",
    "\n",
    "    final_candidates_group_items = group_items[final_candidates, :] # second id mapping (to go back index by final_candidates)\n",
    "    \n",
    "    # simple Monte Carlo method for computing probabilities of linear aggregation strategy ratios (analytical solution not feasible)\n",
    "    # now we want to try many different weights of users and award points to winners based on the weighted ranks\n",
    "\n",
    "    mc_score = np.zeros(len(final_candidates))\n",
    "\n",
    "    for i in range(mc_trials):\n",
    "        # get random weights summing up to 1 for the group members\n",
    "        weights = np.random.random(group_size)\n",
    "        weights /= weights.sum()\n",
    "        \n",
    "        group_items_score = np.sum(weights * final_candidates_group_items, axis=1)\n",
    "        top_n_idx = get_idx_of_top_n(group_items_score, top_n)\n",
    "        mc_score[top_n_idx] += 1\n",
    "\n",
    "    # print(f'MC score: {mc_score}')\n",
    "    top_n_idx = get_idx_of_top_n(mc_score, top_n)\n",
    "    # print(top_n_idx)\n",
    "    # print(final_candidates[top_n_idx])\n",
    "    # now we need to get the original item ids from the final_candidates list and then top_candidates_idx\n",
    "    final_top_candidates = top_candidates_idx[final_candidates[top_n_idx]]\n",
    "    # print(f'Final top candidates: {final_top_candidates}')\n",
    "    return final_top_candidates\n",
    "\n",
    "\n",
    "group_size = 5\n",
    "\n",
    "# load groups\n",
    "groups = pd.read_csv('../notebooks/dfs/groups/kgrec/top_k_10.csv')\n",
    "#concatenate first 5 columns to array of ints\n",
    "groups = groups.iloc[:,:group_size].values\n",
    "# print(groups.shape)\n",
    "# print(groups[0:2])\n",
    "\n",
    "# group_items = []\n",
    "# for group in groups:\n",
    "#     members = {}\n",
    "#     member_items\n",
    "#     for member in group:\n",
    "#         items = get_items_for_users(member)\n",
    "#         members[member] = items\n",
    "#     group_items.append(members)s\n",
    "#     break\n",
    "\n",
    "\n",
    "# first_group = group_items[0]\n",
    "# for member, items in first_group.items():\n",
    "#     print(member, items[0], items[-1])\n",
    "#     break\n",
    "\n",
    "rec_it_avg = []\n",
    "rec_it_lm = []\n",
    "rec_it_fai = []\n",
    "rec_it_xpo = []\n",
    "\n",
    "for group_members in tqdm(groups):\n",
    "    items = get_items_for_users(group_members)\n",
    "\n",
    "    # # avg_algorithm\n",
    "    # top_n_items_avg = avg_algorithm(items, 10)\n",
    "    # rec_it_avg.append(top_n_items_avg)\n",
    "\n",
    "    # # lm_algorithm\n",
    "    # top_n_items_lm = lm_algorithm(items, 10)\n",
    "    # rec_it_lm.append(top_n_items_lm)\n",
    "\n",
    "    # # fai_algorithm\n",
    "    # top_n_items_fai = fai_algorithm(items, 10)\n",
    "    # rec_it_fai.append(top_n_items_fai)\n",
    "\n",
    "    # xpo_algorithm\n",
    "    top_n_items_xpo = xpo_algorithm(items, 10, 100, type='NPO')\n",
    "    rec_it_xpo.append(top_n_items_xpo)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [10, 9, 5, 6] # expected [2,3,1,0]\n",
    "np.array(x).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [18, 1, 2, 5, 6], [1, 2, 3, 4, 5] # expected [12340]\n",
    "\n",
    "def get_rank(score_list_np):\n",
    "    ranks = np.zeros(score_list_np.shape, dtype=np.int32)\n",
    "    ranks[score_list_np.argsort()] = np.arange(start=score_list_np.shape[0], stop=0, step=-1)\n",
    "    print(ranks)\n",
    "\n",
    "np.apply_along_axis(get_rank, 1, np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(np.arange(10), axis=1).repeat(3, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72e4c8b5f0869b81e3c54c1a9c17a5176fed7dccc000e70ae85e6cab596ae0d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
