{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "u_features = np.load('../datasets/movie_lens/mf/U_features.npy')\n",
    "i_features = np.load('../datasets/movie_lens/mf/I_features.npy')\n",
    "print(u_features.shape)\n",
    "print(i_features.shape)\n",
    "\n",
    "def get_items_for_user(user_id):\n",
    "    items_ratings = u_features[:, user_id] @ i_features\n",
    "    items_ids_w_ratings = [(item_id, rating) for item_id, rating in enumerate(items_ratings)]\n",
    "    items_ids_w_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "    return items_ids_w_ratings\n",
    "\n",
    "def get_items_for_users(users_id: List):\n",
    "    items_ratings = i_features.T @ u_features[:, users_id]\n",
    "    # items_ratings = np.minimum(5, np.maximum(0, i_features.T @ u_features[:, users_id]))\n",
    "    return items_ratings\n",
    "    \n",
    "# ratings = get_items_for_users([10,20,30])\n",
    "# ratings.shape\n",
    "\n",
    "def select_top_n_idx(score_list, top_n, top='max', sort=True, exclude_idx=[]):\n",
    "    if top != 'max' and top != 'min':\n",
    "        raise ValueError('top must be either Max or Min')\n",
    "    if top == 'max':\n",
    "        score_list = -score_list\n",
    "\n",
    "    select_top_n = top_n + len(exclude_idx)\n",
    "    top_n_ind = np.argpartition(score_list, select_top_n)[:select_top_n]\n",
    "\n",
    "    if sort:\n",
    "        top_n_ind = top_n_ind[np.argsort(score_list[top_n_ind])]\n",
    "\n",
    "    if exclude_idx:\n",
    "        top_n_ind = [idx for idx in top_n_ind if idx not in exclude_idx]\n",
    "    return top_n_ind[0:top_n]\n",
    "\n",
    "\n",
    "a = np.array([2,1,6,7,8,9,3,4,5,10])\n",
    "assert np.array_equal(select_top_n_idx(a, 3, top='max'), [9, 5, 4])\n",
    "assert np.array_equal(select_top_n_idx(a, 3, top='min'), [1, 0, 6])\n",
    "assert set(select_top_n_idx(a, 3, top='max', sort=False)) == {9, 5, 4}\n",
    "assert set(select_top_n_idx(a, 3, top='min', sort=False)) == {0, 1, 6}\n",
    "\n",
    "assert np.array_equal(select_top_n_idx(a, 3, top='max', exclude_idx=[1]), [9, 5, 4])\n",
    "assert np.array_equal(select_top_n_idx(a, 3, top='min', exclude_idx=[1]), [0, 6, 7])\n",
    "assert set(select_top_n_idx(a, 3, top='max', sort=False, exclude_idx=[1])) == {9, 5, 4}\n",
    "assert set(select_top_n_idx(a, 3, top='min', sort=False, exclude_idx=[1])) == {0, 6, 7}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "\n",
    "# borda count that is limited only to top-max_rel_items, if you are not in the top-max_rel_items, you get 0\n",
    "def get_borda_rel(candidate_group_items_np, max_rel_items):\n",
    "    rel_idx = select_top_n_idx(candidate_group_items_np, max_rel_items, top='max', sort=False)\n",
    "    # print(candidate_group_items_np[rel_idx])\n",
    "    x = candidate_group_items_np[rel_idx]\n",
    "    rel_borda = rankdata(-candidate_group_items_np[rel_idx], method='max')\n",
    "    # print(rel_borda)\n",
    "    \n",
    "    rel_all = np.zeros(len(candidate_group_items_np))\n",
    "    rel_all[rel_idx] = rel_borda\n",
    "    return rel_all\n",
    "\n",
    "x = np.array([1,1,3,8, 10, 100, 11, 28])\n",
    "get_borda_rel(x, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from matplotlib.pyplot import axis\n",
    "\n",
    "def gfar_algorithm(group_items, top_n: int, relevant_max_items: int, n_candidates: int):\n",
    "    group_size = group_items.shape[1]\n",
    "\n",
    "    top_candidates_ids_per_member = np.apply_along_axis(lambda u_items: select_top_n_idx(u_items, n_candidates, sort=False), 0, group_items)\n",
    "    # these are the original items ids\n",
    "    top_candidates_idx = np.array(sorted(set(top_candidates_ids_per_member.flatten())))\n",
    "    # get the candidate group items for each member\n",
    "    candidate_group_items = group_items[top_candidates_idx, :] # this is the first id mapping (to go back to original, index by top_candidates_idx)\n",
    "\n",
    "    borda_rel_of_candidates = np.apply_along_axis(lambda items_for_user: get_borda_rel(items_for_user, relevant_max_items), 0, candidate_group_items)\n",
    "    total_relevance_for_users = borda_rel_of_candidates.sum(axis=0)\n",
    "    p_relevant = borda_rel_of_candidates / total_relevance_for_users\n",
    "\n",
    "    selected_items = []\n",
    "    # this is the inside of the product in calculating the relevance for set of selected\n",
    "    prob_selected_not_relevant = np.ones(group_size)\n",
    "\n",
    "    # top-n times select one item to the final list\n",
    "    for i in range(top_n):\n",
    "        marginal_gain = p_relevant * prob_selected_not_relevant\n",
    "        item_marginal_gain = marginal_gain.sum(axis=1)\n",
    "        # select the item with the highest marginal gain\n",
    "        item_id = select_top_n_idx(item_marginal_gain, 1, exclude_idx=selected_items)[0]\n",
    "        selected_items.append(item_id)\n",
    "\n",
    "        # update the probability of selected items not being relevant\n",
    "        prob_selected_not_relevant *= (1 - p_relevant[item_id])\n",
    "\n",
    "    # now we need to get the original item ids from the final_candidates list and then top_candidates_idx\n",
    "    final_top_candidates = top_candidates_idx[selected_items]\n",
    "\n",
    "    return selected_items\n",
    "\n",
    "\n",
    "group_size = 5\n",
    "\n",
    "# load groups\n",
    "groups = pd.read_csv('../notebooks/dfs/groups/kgrec/top_k_10.csv')\n",
    "#concatenate first 5 columns to array of ints\n",
    "groups = groups.iloc[:,:group_size].values\n",
    "rec_it = []\n",
    "\n",
    "for group_members in tqdm(groups):\n",
    "    items = get_items_for_users(group_members)\n",
    "    top_n_items = gfar_algorithm(items, 10, relevant_max_items=100, n_candidates=1000)\n",
    "    # print(items[top_n_items, :])\n",
    "    rec_it.append(top_n_items)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72e4c8b5f0869b81e3c54c1a9c17a5176fed7dccc000e70ae85e6cab596ae0d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
