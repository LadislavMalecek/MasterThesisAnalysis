{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 162541)\n",
      "(200, 59047)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "u_features = np.load('../datasets/movie_lens/mf/U_features.npy')\n",
    "i_features = np.load('../datasets/movie_lens/mf/I_features.npy')\n",
    "print(u_features.shape)\n",
    "print(i_features.shape)\n",
    "\n",
    "def get_items_for_user(user_id):\n",
    "    items_ratings = u_features[:, user_id] @ i_features\n",
    "    items_ids_w_ratings = [(item_id, rating) for item_id, rating in enumerate(items_ratings)]\n",
    "    items_ids_w_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "    return items_ids_w_ratings\n",
    "\n",
    "def get_items_for_users(users_id: List):\n",
    "    items_ratings = i_features.T @ u_features[:, users_id]\n",
    "    # items_ratings = np.minimum(5, np.maximum(0, i_features.T @ u_features[:, users_id]))\n",
    "    return items_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuzz_dhondt.npy\n",
      "(1000, 10)\n",
      "xpo.npy\n",
      "(1000, 10)\n",
      "lm.npy\n",
      "(1000, 10)\n",
      "ep_fuzz_dhondt.npy\n",
      "(1000, 10)\n",
      "fai.npy\n",
      "(1000, 10)\n",
      "gfar.npy\n",
      "(1000, 10)\n",
      "npo.npy\n",
      "(1000, 10)\n",
      "avg.npy\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pyparsing import NamedTuple\n",
    "\n",
    "\n",
    "group_size = 5\n",
    "group_type = 'top_k'\n",
    "\n",
    "# load groups\n",
    "groups = pd.read_csv('../notebooks/dfs/groups/kgrec/top_k_10.csv')\n",
    "#concatenate first 5 columns to array of ints\n",
    "groups = groups.iloc[:,:group_size].values\n",
    "\n",
    "group_size = 5\n",
    "group_type = 'top_k'\n",
    "\n",
    "# for all files in the folder\n",
    "for file in os.listdir(f'../results/gs-{group_size}/{group_type}'):\n",
    "    print(file)\n",
    "    data = np.load(f'../results/gs-{group_size}/{group_type}/{file}')\n",
    "    print(data.shape)\n",
    "\n",
    "    for \n",
    "\n",
    "# for group_members in tqdm(groups):\n",
    "#     items = get_items_for_users(group_members)\n",
    "\n",
    "#     # xpo_algorithm\n",
    "#     top_n_items_xpo = xpo_algorithm(items, 10, 30, type='XPO', mc_trials=100)\n",
    "#     top_n_items_npo = xpo_algorithm(items, 10, 30, type='NPO', mc_trials=100)\n",
    "#     rec_it_xpo.append(top_n_items_xpo)\n",
    "#     rec_it_npo.append(top_n_items_npo)\n",
    "\n",
    "\n",
    "class Result(NamedTuple):\n",
    "    alg: str\n",
    "    metric: str\n",
    "    value: float\n",
    "\n",
    "class AlgRecommendations(NamedTuple):\n",
    "    alg_name: str\n",
    "    # dict indexed by groupId\n",
    "    group_recommendations: Dict[int, List[int]] = {}\n",
    "\n",
    "#calculates discounted cumulative gain on the array of relevances\n",
    "def calculate_dcg(values):\n",
    "    values = np.array(values)\n",
    "    if values.size: #safety check\n",
    "        return np.sum(values / np.log2(np.arange(2, values.size + 2)))\n",
    "    return 0.0   \n",
    "\n",
    "def calculate_per_user_IDCG(test_data, topk_size):\n",
    "    users = range(test_data.shape[0])\n",
    "    idcg_per_user = {}\n",
    "    for user in users:        \n",
    "        per_user_items = test_data[user] \n",
    "        sorted_items = np.sort(per_user_items)[::-1]\n",
    "        sorted_items = sorted_items[0:20]\n",
    "        \n",
    "        idcg = calculate_dcg(sorted_items)\n",
    "        idcg_per_user[user] = idcg\n",
    "        \n",
    "        #print(sorted_items)\n",
    "        #print(idcg)\n",
    "        #exit()\n",
    "        \n",
    "    return idcg_per_user\n",
    "\n",
    "def compute_metrics(ground_truth: np.ndarray, groups: List[List[int]], items_recommended: List[List[int]]) -> List[Result]:\n",
    "    # test_data are triplets: user_id, item_id, and rating\n",
    "    #LP: test data is matrix user_id x item_id !!!!!! a ja si rikal, jakto ze ti to prirazeni funguje...\n",
    "    idcg_per_user = calculate_per_user_IDCG(test_data, 20)\n",
    "    \n",
    "    \n",
    "    avg_rating = []\n",
    "    min_rating = []\n",
    "    minmax_rating = []\n",
    "    std_rating = []\n",
    "    \n",
    "    avg_nDCG_rating = []\n",
    "    min_nDCG_rating = []\n",
    "    minmax_nDCG_rating = []\n",
    "    std_nDCG_rating = []\n",
    "        \n",
    "    for group, items in zip(groups, items_recommended):\n",
    "        group_users_sum_ratings = []\n",
    "        group_users_ndcg_ratings = []\n",
    "        group_id = group.id \n",
    "\n",
    "        for group_user_id in group:\n",
    "            user_sum = 0.0\n",
    "            user_list = []\n",
    "            for item_id in items:\n",
    "                rating = ground_truth[group_user_id, item_id]\n",
    "                user_sum += rating\n",
    "                user_list.append(rating)\n",
    "            ndcg = calculate_dcg(user_list) / idcg_per_user[group_user_id]   \n",
    "            \n",
    "            group_users_sum_ratings.append(user_sum)\n",
    "            group_users_ndcg_ratings.append(ndcg)\n",
    "        #TODO: quick&dirty code - consider revising   \n",
    "        \n",
    "        group_users_mean_ratings = [i/len(rec_for_group) for i in group_users_sum_ratings] \n",
    "        avg_rating.append(np.average(group_users_mean_ratings)) \n",
    "        min = np.min(group_users_mean_ratings)\n",
    "        min_rating.append(min) \n",
    "        max = np.max(group_users_mean_ratings)\n",
    "        minmax_rating.append(0.0 if max == 0.0 else min/max)\n",
    "        std_rating.append(np.std(group_users_mean_ratings)) \n",
    "        \n",
    "        avg_nDCG_rating.append(np.average(group_users_ndcg_ratings)) \n",
    "        min = np.min(group_users_ndcg_ratings)\n",
    "        min_nDCG_rating.append(min) \n",
    "        max = np.max(group_users_ndcg_ratings)\n",
    "        minmax_nDCG_rating.append(0.0 if max == 0.0 else min/max)\n",
    "        std_nDCG_rating.append(np.std(group_users_ndcg_ratings))         \n",
    "        \n",
    "    results = []\n",
    "    results.append(Result(alg_data.alg_name, \"AR_avg\", np.average(avg_rating)))\n",
    "    results.append(Result(alg_data.alg_name, \"AR_min\", np.average(min_rating)))\n",
    "    results.append(Result(alg_data.alg_name, \"AR_min/max\", np.average(minmax_rating)))\n",
    "    results.append(Result(alg_data.alg_name, \"AR_std\", np.average(std_rating)))\n",
    "    \n",
    "    results.append(Result(alg_data.alg_name, \"nDCG_avg\", np.average(avg_nDCG_rating)))\n",
    "    results.append(Result(alg_data.alg_name, \"nDCG_min\", np.average(min_nDCG_rating)))\n",
    "    results.append(Result(alg_data.alg_name, \"nDCG_min/max\", np.average(minmax_nDCG_rating)))\n",
    "    results.append(Result(alg_data.alg_name, \"nDCG_std\", np.average(std_nDCG_rating)))    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys, os\n",
    "from typing import Dict, List, NamedTuple, Tuple\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# # fold, directory\n",
    "# def get_folds(data_dir: str) -> List[Tuple[int, str]]:\n",
    "#     folds = []\n",
    "#     for dir in [f for f in Path(data_dir).iterdir() if f.is_dir()]:\n",
    "#         dir_name = os.path.basename(dir)\n",
    "#         if str(dir_name).isnumeric():\n",
    "#             folds.append((int(dir_name), str(dir)))\n",
    "#     folds.sort()\n",
    "#     return folds\n",
    "\n",
    "# returns 2d numpy array where 1. index is userId and 2. index is itemId, values are float ratings\n",
    "def load_data(data_dir: str, fold: int) -> np.ndarray:\n",
    "    return np.load(os.path.join(data_dir, str(fold), \"mf_data.npy\"))\n",
    "\n",
    "class Group(NamedTuple):\n",
    "    id: int\n",
    "    members: List[int]\n",
    "\n",
    "# group data must be in file formated with groupId, userid1, userid2...\n",
    "# separated by tabs\n",
    "def load_group_data(data_dir: str, group_type: str, group_size: int) -> List[Group]:\n",
    "    groups = []\n",
    "    filename = group_type + \"_group_\" + str(group_size)\n",
    "    path = os.path.join(data_dir, filename)\n",
    "    with open(path) as group_file:\n",
    "        lines = group_file.readlines()\n",
    "        for line in lines:\n",
    "            items = line.replace('\\n', '').split(\"\\t\")\n",
    "            items = list(map(int, items))\n",
    "            groups.append(Group(items[0], items[1:]))\n",
    "            if len(items) < group_size + 1:\n",
    "                raise Exception(\"Group file invalid: \" + path)\n",
    "    return groups\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_recommendation_files(data_dir: str, fold: int, group: str, group_size: int) -> List[str]:\n",
    "    rec_path = os.path.join(data_dir, str(fold), group, str(group_size)) \n",
    "    return list([str(f) for f in Path(rec_path).iterdir() if f.is_file()])\n",
    "\n",
    "class AlgRecommendations(NamedTuple):\n",
    "    alg_name: str\n",
    "    # dict indexed by groupId\n",
    "    group_recommendations: Dict[int, List[int]] = {} \n",
    "\n",
    "\n",
    "# items are sorted from best to worst\n",
    "# returns list of tuples where first is the agreg name and second is dictionary of recommendations indexed by group id\n",
    "def load_agregated_recommendations(data_dir: str, fold: int, group: str, group_size: int) -> List[AlgRecommendations]:\n",
    "    files = get_recommendation_files(data_dir, fold, group, group_size)\n",
    "    returnList = []\n",
    "    for file in files:\n",
    "        recommendationsMap = defaultdict(list) \n",
    "        with open(file) as recommendation_file:\n",
    "            lines = recommendation_file.readlines()\n",
    "            for line in lines:\n",
    "                items = line.replace('\\n', '').split(\"\\t\")[:2]\n",
    "                items = list(map(int, items))\n",
    "                group_id = items[0]\n",
    "                recommendationsMap[group_id].append(items[1])\n",
    "        alg_name = os.path.basename(file)\n",
    "        returnList.append(AlgRecommendations(alg_name, recommendationsMap))\n",
    "    return returnList\n",
    "\n",
    "#calculates discounted cumulative gain on the array of relevances\n",
    "def calculate_dcg(values):\n",
    "    values = np.array(values)\n",
    "    if values.size: #safety check\n",
    "        return np.sum(values / np.log2(np.arange(2, values.size + 2)))\n",
    "    return 0.0    \n",
    "\n",
    "#order items of user, cut best topk_size, calculate DCG of the cut\n",
    "#test_data = uidxoid matrix of ratings\n",
    "#topk_size = volume of items per user on which to calculate IDCG\n",
    "#return dictionary {userID:IDCG_value}\n",
    "def calculate_per_user_IDCG(test_data, topk_size):\n",
    "    users = range(test_data.shape[0])\n",
    "    idcg_per_user = {}\n",
    "    for user in users:        \n",
    "        per_user_items = test_data[user] \n",
    "        sorted_items = np.sort(per_user_items)[::-1]\n",
    "        sorted_items = sorted_items[0:20]\n",
    "        \n",
    "        idcg = calculate_dcg(sorted_items)\n",
    "        idcg_per_user[user] = idcg\n",
    "        \n",
    "        #print(sorted_items)\n",
    "        #print(idcg)\n",
    "        #exit()\n",
    "        \n",
    "    return idcg_per_user\n",
    "        \n",
    "    \n",
    "\n",
    "class Result(NamedTuple):\n",
    "    alg: str\n",
    "    metric: str\n",
    "    value: float\n",
    "\n",
    "  \n",
    "\n",
    "def compute_metrics(test_data: np.ndarray, groups: List[Group], alg_data: AlgRecommendations) -> List[Result]:\n",
    "    # test_data are triplets: user_id, item_id, and rating\n",
    "    #LP: test data is matrix user_id x item_id !!!!!! a ja si rikal, jakto ze ti to prirazeni funguje...\n",
    "    idcg_per_user = calculate_per_user_IDCG(test_data, 20)\n",
    "    \n",
    "    \n",
    "    avg_rating = []\n",
    "    min_rating = []\n",
    "    minmax_rating = []\n",
    "    std_rating = []\n",
    "    \n",
    "    avg_nDCG_rating = []\n",
    "    min_nDCG_rating = []\n",
    "    minmax_nDCG_rating = []\n",
    "    std_nDCG_rating = []\n",
    "        \n",
    "    for group in groups:\n",
    "        group_users_sum_ratings = []\n",
    "        group_users_ndcg_ratings = []\n",
    "        group_id = group.id \n",
    "        rec_for_group = alg_data.group_recommendations[group_id]\n",
    "        for group_user_id in group.members:\n",
    "            user_sum = 0.0\n",
    "            user_list = []\n",
    "            for item_id in rec_for_group:\n",
    "                rating = test_data[group_user_id, item_id]\n",
    "                #print(group_user_id, item_id, rating)\n",
    "                #print(type(test_data))\n",
    "                #print(test_data.shape)\n",
    "                #print(test_data[group_user_id])\n",
    "                #exit()\n",
    "                user_sum += rating\n",
    "                user_list.append(rating)\n",
    "            ndcg = calculate_dcg(user_list) / idcg_per_user[group_user_id]   \n",
    "            \n",
    "            group_users_sum_ratings.append(user_sum)\n",
    "            group_users_ndcg_ratings.append(ndcg)\n",
    "        #TODO: quick&dirty code - consider revising   \n",
    "        \n",
    "        group_users_mean_ratings = [i/len(rec_for_group) for i in group_users_sum_ratings] \n",
    "        avg_rating.append(np.average(group_users_mean_ratings)) \n",
    "        min = np.min(group_users_mean_ratings)\n",
    "        min_rating.append(min) \n",
    "        max = np.max(group_users_mean_ratings)\n",
    "        minmax_rating.append(0.0 if max == 0.0 else min/max)\n",
    "        std_rating.append(np.std(group_users_mean_ratings)) \n",
    "        \n",
    "        avg_nDCG_rating.append(np.average(group_users_ndcg_ratings)) \n",
    "        min = np.min(group_users_ndcg_ratings)\n",
    "        min_nDCG_rating.append(min) \n",
    "        max = np.max(group_users_ndcg_ratings)\n",
    "        minmax_nDCG_rating.append(0.0 if max == 0.0 else min/max)\n",
    "        std_nDCG_rating.append(np.std(group_users_ndcg_ratings))         \n",
    "        \n",
    "    results = []\n",
    "    results.append(Result(alg_data.alg_name, \"AR_avg\", np.average(avg_rating)))\n",
    "    results.append(Result(alg_data.alg_name, \"AR_min\", np.average(min_rating)))\n",
    "    results.append(Result(alg_data.alg_name, \"AR_min/max\", np.average(minmax_rating)))\n",
    "    results.append(Result(alg_data.alg_name, \"AR_std\", np.average(std_rating)))\n",
    "    \n",
    "    results.append(Result(alg_data.alg_name, \"nDCG_avg\", np.average(avg_nDCG_rating)))\n",
    "    results.append(Result(alg_data.alg_name, \"nDCG_min\", np.average(min_nDCG_rating)))\n",
    "    results.append(Result(alg_data.alg_name, \"nDCG_min/max\", np.average(minmax_nDCG_rating)))\n",
    "    results.append(Result(alg_data.alg_name, \"nDCG_std\", np.average(std_nDCG_rating)))    \n",
    "    return results\n",
    "\n",
    "\n",
    "def process_fold(groups: List[Group], data_dir: str, fold: int, group: str, group_size: int) -> List[Result]:\n",
    "    algs_data = load_agregated_recommendations(data_dir, fold, group, group_size)\n",
    "    test_data = load_data(data_dir, fold)\n",
    "    results = []\n",
    "    for alg_data in algs_data:\n",
    "        results.extend(compute_metrics(test_data, groups, alg_data))\n",
    "    #for result in results:\n",
    "    #    print(result)\n",
    "    return results\n",
    "\n",
    "def main(data_folder, group_type, group_size):\n",
    "    print(data_folder, group_type, group_size)\n",
    "    folds = get_folds(data_folder)\n",
    "    groups: List[Group] = load_group_data(data_folder, group_type, int(group_size))\n",
    "    \n",
    "    results = []\n",
    "    for fold, _ in folds:\n",
    "        results.extend(process_fold(groups, data_folder, fold, group_type, int(group_size)))\n",
    "\n",
    "        \n",
    "    algs = set(map(lambda x:x.alg, results))\n",
    "    metrics = list(set(map(lambda x:x.metric, results)))\n",
    "    print(metrics)\n",
    "    metrics.sort()\n",
    "    print(metrics)\n",
    "    res = \"alg,group_type,group_size\" + \",\" + \",\".join(metrics)+\"\\n\"\n",
    "    for alg in algs:\n",
    "        values = [alg, group_type, str(group_size)]\n",
    "        for metric in metrics:\n",
    "            value = np.average([v.value for v in results if v.alg == alg and v.metric == metric])\n",
    "            value = round(value,3)\n",
    "            values.append(str(value))\n",
    "        res += \",\".join(values)+\"\\n\"\n",
    "    return res\n",
    "\n",
    "        \n",
    "\n",
    "# # if __name__ == \"__main__\":\n",
    "#     # for group_type in [\"sim\", \"div\", \"random\"]:\n",
    "# for group_size in [\"2\",\"3\",\"4\",\"8\"]:\n",
    "#     f = open(\"results/result_\"+group_type+\"_\"+group_size,\"w\")\n",
    "#     results = main(\"data/ml1m\", group_type, group_size)\n",
    "    \n",
    "#     f.write(results)\n",
    "\n",
    "    #args = sys.argv[1:]\n",
    "    #print(args)\n",
    "    #main(args[0], args[1], args[2])\n",
    "    #main(\"data/ml1m\", \"sim\", \"2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72e4c8b5f0869b81e3c54c1a9c17a5176fed7dccc000e70ae85e6cab596ae0d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
