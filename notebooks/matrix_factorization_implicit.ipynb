{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook used to create the integration for implicit matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Implements Alternating Least Squares (ALS) to create a recommender system for a subset of the Netflix dataset.\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "from scipy.sparse import csc_matrix, csr_matrix\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ray\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "from more_itertools import chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id\n",
      "0        0        0\n",
      "1        0        1\n",
      "2        0        2\n",
      "3        0        3\n",
      "4        0        4\n",
      "Number of users:  5199\n",
      "Number of items:  8640\n"
     ]
    }
   ],
   "source": [
    "file, out_dir, n_features = '../datasets/kgrec/music_ratings.csv.gz', '../datasets/kgrec/mf/', 50\n",
    "# file, out_dir, n_features = '../datasets/spotify/ratings.csv.gz', '../datasets/spotify/mf/', 300\n",
    "\n",
    "original_data = pd.read_csv(file)\n",
    "\n",
    "print(original_data.head())\n",
    "# chceck ids\n",
    "assert original_data['user_id'].nunique() == original_data['user_id'].max() + 1\n",
    "assert original_data['item_id'].nunique() == original_data['item_id'].max() + 1\n",
    "\n",
    "print('Number of users: ', original_data['user_id'].nunique())\n",
    "print('Number of items: ', original_data['item_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only users with at least n ratings\n",
    "n = 10\n",
    "num_ratings = original_data.groupby('user_id').size()\n",
    "index_size_ok = num_ratings[num_ratings >= n].index\n",
    "index_size_low = num_ratings[num_ratings < n].index\n",
    "original_data_ok = original_data[original_data['user_id'].isin(index_size_ok)]\n",
    "original_data_low = original_data[original_data['user_id'].isin(index_size_low)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5199, 8640)\n",
      "(5199, 8640)\n"
     ]
    }
   ],
   "source": [
    "def load_and_process_df():\n",
    "    '''\n",
    "    Loads a dataframe from a file and returns a sparse matricies.\n",
    "    '''\n",
    "    df = original_data_ok.copy()\n",
    "    df_low = original_data_low.copy()\n",
    "\n",
    "    if 'user_id' not in df.columns or 'item_id' not in df.columns:\n",
    "        raise Exception('Dataframe does not have user_id and item_id columns')\n",
    "    if not 'rating' in df.columns:\n",
    "        df['rating'] = 1\n",
    "        df_low['rating'] = 1\n",
    "    \n",
    "    df = df[['user_id', 'item_id', 'rating']]\n",
    "    df_low = df_low[['user_id', 'item_id', 'rating']]\n",
    "\n",
    "\n",
    "    # split to training and testing data 80:20 for each user\n",
    "    training, testing = train_test_split(df, test_size=0.2, stratify=df['user_id'])\n",
    "    # training = pd.concat([training, df_low])\n",
    "\n",
    "    num_of_users = df['user_id'].max() + 1\n",
    "    num_of_items = df['item_id'].max() + 1\n",
    "\n",
    "    training_data_csc = csc_matrix((training['rating'], (training['user_id'], training['item_id'])), shape=(num_of_users, num_of_items))\n",
    "    testing_data_csc = csc_matrix((testing['rating'], (testing['user_id'], testing['item_id'])), shape=(num_of_users, num_of_items))\n",
    "    \n",
    "    # check if the last value is only in training data xor testing data\n",
    "    # print(training_data)\n",
    "    uid = int(df.iloc[-1]['user_id'])\n",
    "    iid = int(df.iloc[-1]['item_id'])\n",
    "    rating = df.iloc[-1].rating\n",
    "    in_train = training_data_csc[uid, iid] == rating\n",
    "    in_test = testing_data_csc[df.iloc[-1]['user_id'], df.iloc[-1]['item_id']] == df.iloc[-1].rating\n",
    "    assert (in_train and not in_test) or (not in_train and in_test), 'Dataframe is not split correctly'\n",
    "    \n",
    "    return training_data_csc, testing_data_csc, num_of_users, num_of_items\n",
    "\n",
    "\n",
    "training_data_csc, testing_data_csc, number_of_users, number_of_items = load_and_process_df()\n",
    "\n",
    "print(training_data_csc.shape)\n",
    "print(testing_data_csc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68d5d44a6b7435cabcc925da022fd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import implicit\n",
    "\n",
    "\n",
    "input = '../datasets/kgrec/music_ratings.csv.gz'\n",
    "factors = 50\n",
    "\n",
    "\n",
    "model = implicit.als.AlternatingLeastSquares(factors=factors, num_threads=10)\n",
    "# train the model on a sparse matrix of user/item/confidence weights\n",
    "\n",
    "# we need crs matrix for implicit library as specified in the documentation\n",
    "# user_items: csr_matrix\n",
    "#   Matrix of confidences for the liked items. This matrix should be a csr_matrix where\n",
    "#   the rows of the matrix are the user, the columns are the items liked by that user,\n",
    "#   and the value is the confidence that the user liked the item.\n",
    "\n",
    "user_item_data_csr = training_data_csc.tocsr()\n",
    "model.fit(user_item_data_csr, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features saved to ../datasets/kgrec/mf/\n",
      "U_features shape: (5199, 50)\n",
      "I_features shape: (8640, 50)\n",
      "[[ 0.32297722  0.14018077 -0.18361667 ...  0.32090026  0.14438957\n",
      "   0.41769338]\n",
      " [-0.47638202 -0.17443427 -0.04962534 ... -0.32596985  0.23652582\n",
      "  -0.79392034]\n",
      " [ 0.336984    0.3637985  -0.26695216 ... -0.02917717  0.15864246\n",
      "   0.60157067]\n",
      " ...\n",
      " [-0.27085918 -0.12923804 -0.26580304 ... -0.17377138  0.7439807\n",
      "   0.16454127]\n",
      " [ 0.325364   -0.16725653  0.31061834 ... -0.8237092  -0.20028614\n",
      "  -0.5407357 ]\n",
      " [ 0.13770361 -0.5618404   0.37424856 ... -0.46694812 -0.35027254\n",
      "  -0.6047742 ]]\n",
      "[[ 1.6076101e-02  3.0562010e-02 -5.7015836e-02 ...  2.5372272e-02\n",
      "  -1.6897468e-02 -9.4786088e-04]\n",
      " [ 4.4864896e-03 -7.1100001e-03  7.9561817e-03 ...  9.2834402e-03\n",
      "   2.3293081e-03  1.8198498e-03]\n",
      " [ 1.4858595e-02  2.0564320e-02 -5.5074822e-02 ...  2.0950746e-02\n",
      "  -1.1320139e-02  3.4459867e-03]\n",
      " ...\n",
      " [ 1.2216844e-03 -2.5652989e-03 -1.7900961e-04 ... -1.6647113e-04\n",
      "   1.8422551e-03  1.0186286e-03]\n",
      " [ 2.5267983e-04 -1.4542312e-04 -1.0257905e-03 ... -1.1401268e-03\n",
      "   1.2207195e-03  3.4547289e-04]\n",
      " [ 9.2195970e-04  8.4163235e-05 -7.8475906e-04 ...  6.7309593e-04\n",
      "   2.6136939e-04  2.4364491e-03]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "testing_data_csc\n",
    "\n",
    "U_features = model.user_factors\n",
    "I_features = model.item_factors\n",
    "\n",
    "np.save(out_dir + 'U_features.npy', U_features)\n",
    "np.save(out_dir + 'I_features.npy', I_features)\n",
    "\n",
    "print('features saved to', out_dir)\n",
    "\n",
    "# print statistics about features\n",
    "print('U_features shape: {0}'.format(U_features.shape))\n",
    "print('I_features shape: {0}'.format(I_features.shape))\n",
    "print(U_features)\n",
    "print(I_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a quick evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_csr = testing_data_csc.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_predictions = []\n",
    "for user_i in range(number_of_users):\n",
    "    x = testing_data_csr[user_i, :]\n",
    "    u_features = U_features[user_i]\n",
    "    # print('user', u_features.shape)\n",
    "    training_item_features = I_features[x.indices]\n",
    "    # print('training_item_features', training_item_features.shape)\n",
    "    predictions = np.dot(training_item_features, u_features)\n",
    "    # print('predictions', predictions.shape)\n",
    "    user_predictions.append(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = list(map(lambda x: np.array(x).mean(), user_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5199.000000\n",
       "mean        0.206553\n",
       "std         0.079218\n",
       "min         0.021580\n",
       "25%         0.147811\n",
       "50%         0.199834\n",
       "75%         0.258635\n",
       "max         0.523911\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get statistics about averages\n",
    "pd.Series(averages).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Jun  7 2022, 13:28:04) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b9e6d427c7ffb7051e7a4a630c7ee86c58c59453b387f56f3562822577aaf7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
