{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains an evaluation for the long-term scenario\n",
    "\n",
    "Simply run it as the last step of the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "sys.path.append(os.path.join(sys.path[0], '..'))\n",
    "\n",
    "from evaluation.evaluation_utils import calculate_dcg, RatingsRetriever, load_mf_matrices, load_groups, get_top_dict, get_group_size_from_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LongtermMetrics:\n",
    "    avg_ratings: List[float] = field(default_factory=list)\n",
    "    min_ratings: List[float] = field(default_factory=list)\n",
    "    minmax_ratings: List[float] = field(default_factory=list)\n",
    "    std_ratings: List[float] = field(default_factory=list)\n",
    "\n",
    "    avg_ndcgs_ratings: List[float] = field(default_factory=list)\n",
    "    min_ndcgs_ratings: List[float] = field(default_factory=list)\n",
    "    minmax_ndcgs_ratings: List[float] = field(default_factory=list)\n",
    "    std_ndcgs_ratings: List[float] = field(default_factory=list)\n",
    "\n",
    "    alg_name: str = field(default=None)\n",
    "    group_name: str = field(default=None)\n",
    "\n",
    "    def to_avg_dict(self):\n",
    "        return {\n",
    "            'alg_name': self.alg_name,\n",
    "            'group_name': self.group_name,\n",
    "            'avg_ratings': np.mean(self.avg_ratings),\n",
    "            'min_ratings': np.mean(self.min_ratings),\n",
    "            'minmax_ratings': np.mean(self.minmax_ratings),\n",
    "            'std_ratings': np.mean(self.std_ratings),\n",
    "            'avg_ndcgs_ratings': np.mean(self.avg_ndcgs_ratings),\n",
    "            'min_ndcgs_ratings': np.mean(self.min_ndcgs_ratings),\n",
    "            'minmax_ndcgs_ratings': np.mean(self.minmax_ndcgs_ratings),\n",
    "            'std_ndcgs_ratings': np.mean(self.std_ndcgs_ratings),\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "def calculate_metrics(groups, results, ratings_retriever, idcg_top_k):\n",
    "    # now for each group (set of users), and items that have been recommended to the group\n",
    "    # we calculate, for each user, sum of ratings and ndcg of ratings\n",
    "    metrics = LongtermMetrics()\n",
    "\n",
    "    for group, result in tqdm(list(zip(groups.values, results))):\n",
    "        group_item_ratings = ratings_retriever.get_ratings(group, result)\n",
    "        ratings_user_sum = np.sum(group_item_ratings, axis=1)\n",
    "\n",
    "        dcgs = np.apply_along_axis(calculate_dcg, 1, group_item_ratings)\n",
    "        idcgs = np.array([ratings_retriever.get_user_IDCG(user_id, idcg_top_k) for user_id in group])\n",
    "        ndcgs = dcgs / idcgs\n",
    "\n",
    "        metrics.avg_ratings.append(float(np.mean(ratings_user_sum)))\n",
    "        metrics.min_ratings.append(float(np.min(ratings_user_sum)))\n",
    "        max_ratings = np.max(ratings_user_sum)\n",
    "        metrics.minmax_ratings.append(float(np.divide(np.min(ratings_user_sum), max_ratings, out=np.zeros_like(max_ratings), where=max_ratings!=0)))\n",
    "        metrics.std_ratings.append(float(np.std(ratings_user_sum)))\n",
    "\n",
    "        metrics.avg_ndcgs_ratings.append(float(np.mean(ndcgs)))\n",
    "        metrics.min_ndcgs_ratings.append(float(np.min(ndcgs)))\n",
    "        max_ndcgs = np.max(ndcgs)\n",
    "        metrics.minmax_ndcgs_ratings.append(float(np.divide(np.min(ndcgs), max_ndcgs, out=np.zeros_like(max_ndcgs), where=max_ndcgs!=0)))\n",
    "        metrics.std_ndcgs_ratings.append(float(np.std(ndcgs)))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "    \n",
    "def process_results(mf_path, groups_path, results_path, idcg_top_k):\n",
    "    # first, load the data\n",
    "    u_features, i_features = load_mf_matrices(mf_path)\n",
    "    ratings_retriever = RatingsRetriever(u_features, i_features)\n",
    "    groups = load_groups(groups_path)\n",
    "\n",
    "    # now, for each group type we have results for each algorithm\n",
    "    results = []\n",
    "    for group_name in sorted(os.listdir(results_path)):\n",
    "        # skip if not directory\n",
    "        if not os.path.isdir(os.path.join(results_path, group_name)):\n",
    "            continue\n",
    "\n",
    "        print(f'--- processing group: {group_name}')\n",
    "        group_results = {}\n",
    "        for result_file in os.listdir(os.path.join(results_path, group_name)):\n",
    "            \n",
    "            # skip trace directories\n",
    "            if os.path.isdir(os.path.join(results_path, group_name, result_file)):\n",
    "                continue\n",
    "\n",
    "            result = np.load(os.path.join(results_path, group_name, result_file))\n",
    "            algorithm_name = result_file.split('.')[0]\n",
    "            # print(result_file)\n",
    "            metrics = calculate_metrics(\n",
    "                groups[group_name],\n",
    "                result,\n",
    "                ratings_retriever,\n",
    "                idcg_top_k,\n",
    "            )\n",
    "            metrics.alg_name = algorithm_name\n",
    "            metrics.group_name = group_name\n",
    "\n",
    "            results.append(metrics)\n",
    "    avg_results = pd.DataFrame([result.to_avg_dict() for result in results])\n",
    "    avg_results['group_size'] = avg_results['group_name'].apply(get_group_size_from_name)\n",
    "    return avg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_type_dict = {\n",
    "    'avg_ratings': 'max',\n",
    "    'min_ratings': 'max',\n",
    "    'minmax_ratings': 'max',\n",
    "    'std_ratings' : 'max',\n",
    "    'avg_ndcgs_ratings': 'max',\n",
    "    'min_ndcgs_ratings': 'max',\n",
    "    'minmax_ndcgs_ratings': 'max',\n",
    "    'std_ndcgs_ratings': 'max',\n",
    "}\n",
    "\n",
    "def get_latex_table_data(metrics: LongtermMetrics, all_other_metrics: List[LongtermMetrics]):\n",
    "    res_order = ['avg_ratings', 'min_ratings', 'minmax_ratings', 'avg_ndcgs_ratings', 'min_ndcgs_ratings', 'minmax_ndcgs_ratings']\n",
    "    top_dict = get_top_dict(all_other_metrics, sort_type_dict)\n",
    "    texts = []\n",
    "    for res_name in res_order:\n",
    "        possition = top_dict[res_name].tolist().index(metrics.alg_name)\n",
    "\n",
    "        value = metrics[res_name]\n",
    "        str_value = f'{value:.2f}' if value < 100 else f'{value:.1f}'\n",
    "\n",
    "        if possition == 0:\n",
    "            texts.append(f'\\\\textbf{{{str_value}}}')\n",
    "        elif possition == 1:\n",
    "            texts.append(f'\\\\underline{{{str_value}}}')\n",
    "        # elif possition == 2:\n",
    "        #     texts.append(f'\\\\textit{{{metrics[res_name]:.2f}}}')\n",
    "        else:\n",
    "            texts.append(str_value)\n",
    "    return ' & '.join(texts)\n",
    "\n",
    "\n",
    "def create_latex_table(avg_results, eval_path, dataset_name):\n",
    "    map_alg_name = {\n",
    "        'avg_uniform': 'AVG-U',\n",
    "        'avg': 'AVG',\n",
    "        'dhondt_do': 'DHondtDO',\n",
    "        'ep_fuzz_dhondt': 'EP-Fuzz-DA',\n",
    "    }\n",
    "    alg_order = ['avg_uniform', 'avg', 'dhondt_do', 'ep_fuzz_dhondt']\n",
    "\n",
    "    output_lines = []\n",
    "    output_lines.append('\\\\begin{tabular}{ c | c c c | c c c || c c c | c c c }')\n",
    "    for i, group_size in enumerate([2,3,4,6,8]):\n",
    "        group_order = [f'prs_{group_size}_se=1_noc=1000', f'prs_{group_size}_se=4_noc=1000']\n",
    "        output_lines.append('')\n",
    "        if i != 0:\n",
    "            output_lines.append('\\multicolumn{12}{c}{} \\\\\\\\')\n",
    "        # print('& \\multicolumn{12}{c}{\\\\textbf{group size ' + str(group_size) +'}} \\\\\\\\')\n",
    "        output_lines.append('\\multicolumn{1}{c}{} & \\multicolumn{6}{c}{PRS(M=1)' + f', group size s={group_size}' + '} & \\multicolumn{6}{c}{PRS(M=4)' + f', group size s={group_size}' + '} \\\\\\\\')\n",
    "        output_lines.append('\\multicolumn{1}{c}{} & \\multicolumn{3}{c}{AR} & \\multicolumn{3}{c}{nDCG} & \\multicolumn{3}{c}{AR} & \\multicolumn{3}{c}{nDCG} \\\\\\\\')\n",
    "        output_lines.append('& mean & min & M/M & mean & min & M/M & mean & min & M/M & mean & min & M/M \\\\\\\\')\n",
    "        output_lines.append('\\hline')\n",
    "        for alg in alg_order:\n",
    "            alg_texts = []\n",
    "            for group in group_order:\n",
    "                all_metrics_for_group = avg_results[avg_results['group_name'] == group]\n",
    "                specific_results: LongtermMetrics = all_metrics_for_group[all_metrics_for_group['alg_name'] == alg].iloc[0]\n",
    "                # print(specific_results)\n",
    "                # print in the order\n",
    "                ltx_table_data = get_latex_table_data(specific_results, all_metrics_for_group)\n",
    "                alg_texts.append(ltx_table_data)\n",
    "            \n",
    "            output_lines.append(f'{map_alg_name[alg]} & {\" & \".join(alg_texts)} \\\\\\\\')\n",
    "    output_lines.append('')\n",
    "    output_lines.append('\\end{tabular}')\n",
    "\n",
    "    # make sure the directory exists\n",
    "    os.makedirs(eval_path, exist_ok=True)\n",
    "    # write the lines to file in results_evaluation\n",
    "    results_file_path = os.path.join(eval_path, f'{dataset_name}_longterm_results.tex')\n",
    "    with open(results_file_path, 'w') as f:\n",
    "        f.writelines(line + '\\n' for line in output_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    'kgrec',\n",
    "    'movie_lens',\n",
    "    'movie_lens_small',\n",
    "    'spotify',\n",
    "    'netflix'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U_features shape: (1000000, 300)\n",
      "I_features shape: (2262292, 300)\n",
      "--- processing group: prs_2_se=1_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [24:10<00:00,  1.45s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5628.41it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10573.63it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10780.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_2_se=4_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [23:27<00:00,  1.41s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8617.19it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10690.13it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10850.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_3_se=1_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [34:51<00:00,  2.09s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8231.66it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10206.78it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5855.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_3_se=4_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [34:18<00:00,  2.06s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5232.02it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 7227.25it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 4269.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_4_se=1_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [41:05<00:00,  2.47s/it] \n",
      "100%|██████████| 1000/1000 [00:00<00:00, 7902.57it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8291.38it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10332.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_4_se=4_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [31:55<00:00,  1.92s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 6301.71it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8688.03it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10384.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_6_se=1_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [47:48<00:00,  2.87s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 6906.74it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 9014.95it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 9222.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_6_se=4_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [47:00<00:00,  2.82s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 7282.41it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 7677.07it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 9353.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_8_se=1_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:02:39<00:00,  3.76s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 4591.26it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8428.10it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8622.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_8_se=4_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:02:17<00:00,  3.74s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5218.20it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8227.27it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8613.65it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for dataset in datasets:\n",
    "    data_dir = f'../datasets/{dataset}/'\n",
    "    \n",
    "    mf_path = os.path.join(data_dir, 'mf')\n",
    "    groups_path = os.path.join(data_dir, 'groups')\n",
    "    results_path = os.path.join(data_dir, 'experiment_results', 'longterm')\n",
    "    eval_path = os.path.join(data_dir, 'evaluation_results')\n",
    "\n",
    "    idcg_top_k = 10\n",
    "\n",
    "    results = process_results(mf_path, groups_path, results_path, idcg_top_k)\n",
    "    \n",
    "    os.makedirs(eval_path, exist_ok=True)\n",
    "    results.to_csv(os.path.join(eval_path, f'{dataset}_longterm_results.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_latex_table\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    data_dir = f'../datasets/{dataset}/'\n",
    "    eval_path = os.path.join(data_dir, 'evaluation_results')\n",
    "    results = pd.read_csv(os.path.join(eval_path, f'{dataset}_longterm_results.csv'), index_col=False)\n",
    "    print('create_latex_table')\n",
    "    create_latex_table(results, eval_path, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Jun  7 2022, 13:28:04) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b9e6d427c7ffb7051e7a4a630c7ee86c58c59453b387f56f3562822577aaf7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
