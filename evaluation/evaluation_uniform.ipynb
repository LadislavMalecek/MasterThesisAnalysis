{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains an evaluation for the uniform scenario\n",
    "\n",
    "Simply run it as the last step of the evaluation.\n",
    "\n",
    "Notes:\n",
    "- we now have the matrix factorization model that is telling us our true ratings\n",
    "- together with groups and predicted top items for each group and each algorithm\n",
    "\n",
    "- we can now evaluate the performance of the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "sys.path.append(os.path.join(sys.path[0], '..'))\n",
    "\n",
    "from evaluation.evaluation_utils import calculate_dcg, RatingsRetriever, load_mf_matrices, load_groups, get_top_dict, get_group_size_from_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class UniformMetrics:\n",
    "    avg_ratings: List[float] = field(default_factory=list)\n",
    "    min_ratings: List[float] = field(default_factory=list)\n",
    "    minmax_ratings: List[float] = field(default_factory=list)\n",
    "    std_ratings: List[float] = field(default_factory=list)\n",
    "\n",
    "    avg_ndcgs_ratings: List[float] = field(default_factory=list)\n",
    "    min_ndcgs_ratings: List[float] = field(default_factory=list)\n",
    "    minmax_ndcgs_ratings: List[float] = field(default_factory=list)\n",
    "    std_ndcgs_ratings: List[float] = field(default_factory=list)\n",
    "\n",
    "    alg_name: str = field(default=None)\n",
    "    group_name: str = field(default=None)\n",
    "\n",
    "    def to_avg_dict(self):\n",
    "        return {\n",
    "            'alg_name': self.alg_name,\n",
    "            'group_name': self.group_name,\n",
    "            'avg_ratings': np.mean(self.avg_ratings),\n",
    "            'min_ratings': np.mean(self.min_ratings),\n",
    "            'minmax_ratings': np.mean(self.minmax_ratings),\n",
    "            'std_ratings': np.mean(self.std_ratings),\n",
    "            'avg_ndcgs_ratings': np.mean(self.avg_ndcgs_ratings),\n",
    "            'min_ndcgs_ratings': np.mean(self.min_ndcgs_ratings),\n",
    "            'minmax_ndcgs_ratings': np.mean(self.minmax_ndcgs_ratings),\n",
    "            'std_ndcgs_ratings': np.mean(self.std_ndcgs_ratings),\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "def calculate_uniform_metrics(groups, results, ratings_retriever, idcg_top_k):\n",
    "    # now for each group (set of users), and items that have been recommended to the group\n",
    "    # we calculate, for each user, sum of ratings and ndcg of ratings\n",
    "    metrics = UniformMetrics()\n",
    "\n",
    "    for group, result in tqdm(list(zip(groups.values, results))):\n",
    "        group_item_ratings = ratings_retriever.get_ratings(group, result)\n",
    "        ratings_user_sum = np.sum(group_item_ratings, axis=1)\n",
    "\n",
    "        dcgs = np.apply_along_axis(calculate_dcg, 1, group_item_ratings)\n",
    "        idcgs = np.array([ratings_retriever.get_user_IDCG(user_id, idcg_top_k) for user_id in group])\n",
    "        ndcgs = dcgs / idcgs\n",
    "\n",
    "        metrics.avg_ratings.append(float(np.mean(ratings_user_sum)))\n",
    "        metrics.min_ratings.append(float(np.min(ratings_user_sum)))\n",
    "        max_ratings = np.max(ratings_user_sum)\n",
    "        metrics.minmax_ratings.append(float(np.divide(np.min(ratings_user_sum), max_ratings, out=np.zeros_like(max_ratings), where=max_ratings!=0)))\n",
    "        metrics.std_ratings.append(float(np.std(ratings_user_sum)))\n",
    "\n",
    "        metrics.avg_ndcgs_ratings.append(float(np.mean(ndcgs)))\n",
    "        metrics.min_ndcgs_ratings.append(float(np.min(ndcgs)))\n",
    "        max_ndcgs = np.max(ndcgs)\n",
    "        metrics.minmax_ndcgs_ratings.append(float(np.divide(np.min(ndcgs), max_ndcgs, out=np.zeros_like(max_ndcgs), where=max_ndcgs!=0)))\n",
    "        metrics.std_ndcgs_ratings.append(float(np.std(ndcgs)))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(mf_path, groups_path, results_path, idcg_top_k):\n",
    "    # first, load the data\n",
    "    u_features, i_features = load_mf_matrices(mf_path)\n",
    "    ratings_retriever = RatingsRetriever(u_features, i_features)\n",
    "    groups = load_groups(groups_path)\n",
    "\n",
    "    # now, for each group type we have results for each algorithm\n",
    "    results = []\n",
    "    for group_name in sorted(os.listdir(results_path)):\n",
    "        # skip if not directory\n",
    "        if not os.path.isdir(os.path.join(results_path, group_name)):\n",
    "            continue\n",
    "\n",
    "        group_size = get_group_size_from_name(group_name)\n",
    "\n",
    "        print(f'--- processing group: {group_name}')\n",
    "        group_results = {}\n",
    "        for result_file in os.listdir(os.path.join(results_path, group_name)):\n",
    "            result = np.load(os.path.join(results_path, group_name, result_file))\n",
    "            algorithm_name = result_file.split('.')[0]\n",
    "            # print(result_file)\n",
    "            metrics = calculate_uniform_metrics(\n",
    "                groups[group_name],\n",
    "                result,\n",
    "                ratings_retriever,\n",
    "                idcg_top_k,\n",
    "            )\n",
    "            metrics.alg_name = algorithm_name\n",
    "            metrics.group_name = group_name\n",
    "\n",
    "            results.append(metrics)\n",
    "    avg_results = pd.DataFrame([result.to_avg_dict() for result in results])\n",
    "    avg_results['group_size'] = avg_results['group_name'].apply(get_group_size_from_name)\n",
    "    return avg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_type_dict = {\n",
    "    'avg_ratings': 'max',\n",
    "    'min_ratings': 'max',\n",
    "    'minmax_ratings': 'max',\n",
    "    'std_ratings' : 'max',\n",
    "    'avg_ndcgs_ratings': 'max',\n",
    "    'min_ndcgs_ratings': 'max',\n",
    "    'minmax_ndcgs_ratings': 'max',\n",
    "    'std_ndcgs_ratings': 'max',\n",
    "}\n",
    "\n",
    "def get_latex_table_data(metrics: UniformMetrics, all_other_metrics: List[UniformMetrics]):\n",
    "    res_order = ['avg_ratings', 'min_ratings', 'minmax_ratings', 'avg_ndcgs_ratings', 'min_ndcgs_ratings', 'minmax_ndcgs_ratings']\n",
    "    top_dict = get_top_dict(all_other_metrics, sort_type_dict)\n",
    "    texts = []\n",
    "    for res_name in res_order:\n",
    "        possition = top_dict[res_name].tolist().index(metrics.alg_name)\n",
    "\n",
    "        if possition == 0:\n",
    "            texts.append(f'\\\\textbf{{{metrics[res_name]:.2f}}}')\n",
    "        elif possition == 1:\n",
    "            texts.append(f'\\\\underline{{{metrics[res_name]:.2f}}}')\n",
    "        elif possition == 2:\n",
    "            texts.append(f'\\\\textit{{{metrics[res_name]:.2f}}}')\n",
    "        else:\n",
    "            texts.append(f'{metrics[res_name]:.2f}')\n",
    "    return ' & '.join(texts)\n",
    "\n",
    "\n",
    "def create_latex_table(avg_results, eval_path, dataset_name):\n",
    "    map_alg_name = {\n",
    "        'avg': 'AVG',\n",
    "        'fai': 'FAI',\n",
    "        'lm': 'LM',\n",
    "        'xpo': 'XPO',\n",
    "        'npo': 'NPO',\n",
    "        'gfar': 'GFAR',\n",
    "        'dhondt_do': 'DHondtDO',\n",
    "        'ep_fuzz_dhondt': 'EP-Fuzz-DA',\n",
    "    }\n",
    "    alg_order = ['avg', 'fai', 'lm', 'xpo', 'npo', 'gfar', 'dhondt_do', 'ep_fuzz_dhondt']\n",
    "\n",
    "    output_lines = []\n",
    "    output_lines.append('\\\\begin{tabular}{ c | c c c | c c c || c c c | c c c}')\n",
    "    for i, group_size in enumerate([2,3,4,6,8]):\n",
    "        group_order = [f'prs_{group_size}_se=1_noc=1000', f'prs_{group_size}_se=4_noc=1000']\n",
    "        output_lines.append('')\n",
    "        if i != 0:\n",
    "            output_lines.append('\\multicolumn{12}{c}{} \\\\\\\\')\n",
    "        # print('& \\multicolumn{12}{c}{\\\\textbf{group size ' + str(group_size) +'}} \\\\\\\\')\n",
    "        output_lines.append('\\multicolumn{1}{c}{} & \\multicolumn{6}{c}{PRS(M=1)' + f', group size s={group_size}' + '} & \\multicolumn{6}{c}{PRS(M=4)' + f', group size s={group_size}' + '} \\\\\\\\')\n",
    "        output_lines.append('\\multicolumn{1}{c}{} & \\multicolumn{3}{c}{AR} & \\multicolumn{3}{c}{nDCG} & \\multicolumn{3}{c}{AR} & \\multicolumn{3}{c}{nDCG} \\\\\\\\')\n",
    "        output_lines.append('& mean & min & M/M & mean & min & M/M & mean & min & M/M & mean & min & M/M \\\\\\\\')\n",
    "        output_lines.append('\\hline')\n",
    "        for alg in alg_order:\n",
    "            alg_texts = []\n",
    "            for group in group_order:\n",
    "                all_metrics_for_group = avg_results[avg_results['group_name'] == group]\n",
    "                specific_results: UniformMetrics = all_metrics_for_group[all_metrics_for_group['alg_name'] == alg].iloc[0]\n",
    "                # print(specific_results)\n",
    "                # print in the order\n",
    "                ltx_table_data = get_latex_table_data(specific_results, all_metrics_for_group)\n",
    "                alg_texts.append(ltx_table_data)\n",
    "            \n",
    "            output_lines.append(f'{map_alg_name[alg]} & {\" & \".join(alg_texts)} \\\\\\\\')\n",
    "    output_lines.append('')\n",
    "    output_lines.append('\\end{tabular}')\n",
    "\n",
    "    # make sure the directory exists\n",
    "    os.makedirs(eval_path, exist_ok=True)\n",
    "    # write the lines to file in results_evaluation\n",
    "    results_file_path = os.path.join(eval_path, f'{dataset_name}_uniform_results.tex')\n",
    "    with open(results_file_path, 'w') as f:\n",
    "        f.writelines(line + '\\n' for line in output_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U_features shape: (1000000, 300)\n",
      "I_features shape: (2262292, 300)\n",
      "--- processing group: prs_2_se=1_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [18:14<00:00,  1.09s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 6662.85it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 12787.55it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 12691.17it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 12916.56it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 12845.75it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 12888.10it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 13011.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_2_se=4_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [18:20<00:00,  1.10s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 6199.13it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 12453.47it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 12510.30it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 12678.43it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 12379.11it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 12653.07it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 12638.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_3_se=1_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [26:59<00:00,  1.62s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 6607.07it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11709.20it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11840.16it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11645.64it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11591.02it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11576.05it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11897.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_3_se=4_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [27:56<00:00,  1.68s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5114.59it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11956.43it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 12173.18it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11972.20it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11899.71it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 12003.55it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11680.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_4_se=1_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [36:34<00:00,  2.19s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3956.00it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11474.61it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11553.89it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11375.43it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11450.06it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11604.01it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11548.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_4_se=4_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [35:11<00:00,  2.11s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5466.86it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11029.25it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11326.44it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11155.12it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11302.99it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11429.62it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 11316.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_6_se=1_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [53:32<00:00,  3.21s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3703.91it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10252.39it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10305.54it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10183.61it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10362.06it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10496.39it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10432.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_6_se=4_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [51:52<00:00,  3.11s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5135.13it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10398.90it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10400.09it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10426.98it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10317.15it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10153.83it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10049.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_8_se=1_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:07:55<00:00,  4.08s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 4267.21it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 9440.66it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 9422.86it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 9360.93it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 9423.56it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 9467.01it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 9217.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- processing group: prs_8_se=4_noc=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:08:09<00:00,  4.09s/it]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 6061.48it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8927.55it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 9091.15it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 9121.48it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 9097.27it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 9012.74it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 9299.80it/s]\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    'kgrec',\n",
    "    'movie_lens',\n",
    "    'movie_lens_small',\n",
    "    'spotify',\n",
    "    'netflix'\n",
    "]\n",
    "\n",
    "for dataset in datasets:\n",
    "    data_dir = f'../datasets/{dataset}/'\n",
    "    \n",
    "    mf_path = os.path.join(data_dir, 'mf')\n",
    "    groups_path = os.path.join(data_dir, 'groups')\n",
    "    results_path = os.path.join(data_dir, 'experiment_results', 'uniform')\n",
    "    eval_path = os.path.join(data_dir, 'evaluation_results')\n",
    "\n",
    "    idcg_top_k = 10\n",
    "\n",
    "    results = process_results(mf_path, groups_path, results_path, idcg_top_k)\n",
    "    \n",
    "    os.makedirs(eval_path, exist_ok=True)\n",
    "    results.to_csv(os.path.join(eval_path, f'{dataset}_uniform_results.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_latex_table\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    data_dir = f'../datasets/{dataset}/'\n",
    "    eval_path = os.path.join(data_dir, 'evaluation_results')\n",
    "    results = pd.read_csv(os.path.join(eval_path, f'{dataset}_uniform_results.csv'), index_col=False)\n",
    "    print('create_latex_table')\n",
    "    create_latex_table(results, eval_path, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Jun  7 2022, 13:28:04) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b9e6d427c7ffb7051e7a4a630c7ee86c58c59453b387f56f3562822577aaf7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
